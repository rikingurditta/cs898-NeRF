{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092f55b2-e5c6-45be-a7b9-049261df3573",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env HSA_OVERRIDE_GFX_VERSION=\"10.3.1 python\"\n",
    "import torch\n",
    "from torch.autograd import Variable as V\n",
    "from torchvision.io import read_image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49a4f86-e76d-4093-bd83-c43a937ff006",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.autograd.set_detect_anomaly(False)  # use to detect nans (SLOW!!)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # works for ROCm too\n",
    "    print('cuda devices:', torch.cuda.device_count())\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f'\\t{torch.cuda.get_device_properties(i).name}')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "torch.set_default_device(device)\n",
    "dtype = torch.float\n",
    "torch.set_default_dtype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebc88c6-69bd-4c42-8270-dd77a47becb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeRF2d(torch.nn.Module):\n",
    "    def __init__(self, res=100, samples_per_ray=100, focal_length=0.01, camera_size=0.01,\n",
    "                 layer_size=64, enc=False, x_enc_dim=10, dir_enc_dim=6):\n",
    "        super().__init__()\n",
    "        self.layer_size = layer_size\n",
    "        def enc_n(x, n):\n",
    "            out = torch.zeros((x.shape[0], n * 4))\n",
    "            xs = x[:, 0]\n",
    "            ys = x[:, 1]\n",
    "            for i in range(n):\n",
    "                out[:, i * 4 + 0] = torch.cos(i * xs)\n",
    "                out[:, i * 4 + 1] = torch.sin(i * xs)\n",
    "                out[:, i * 4 + 2] = torch.cos(i * ys)\n",
    "                out[:, i * 4 + 3] = torch.sin(i * ys)\n",
    "            return out\n",
    "    \n",
    "        x_input_size = 2\n",
    "        dir_input_size = 2\n",
    "        self.enc_x_func = lambda x: x\n",
    "        self.enc_dir_func = lambda dir: dir\n",
    "        \n",
    "        if enc:\n",
    "            self.enc_x_func = lambda x: enc_n(x, x_enc_dim)\n",
    "            self.enc_dir_func = lambda dir: enc_n(dir, dir_enc_dim)\n",
    "            x_input_size = 4 * x_enc_dim\n",
    "            dir_input_size = 4 * dir_enc_dim\n",
    "\n",
    "        self.d1 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(x_input_size, layer_size),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(layer_size, layer_size),\n",
    "            torch.nn.LeakyReLU(),\n",
    "        )\n",
    "        self.d2 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(layer_size + x_input_size, layer_size),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(layer_size, 4)\n",
    "        )\n",
    "        self.res = res\n",
    "        self.max_dist = 2\n",
    "        self.focal_length = focal_length\n",
    "        self.samples_per_ray = samples_per_ray\n",
    "        self.camera_size = camera_size\n",
    "        print(f'res: {res}\\n'\n",
    "              f'max_dist: {self.max_dist}\\n'\n",
    "              f'focal_length: {focal_length}\\n'\n",
    "              f'samples_per_ray: {samples_per_ray}\\n'\n",
    "              f'camera_size: {camera_size}\\n'\n",
    "              f'fov: {2 * np.arctan2(camera_size / 2, focal_length) * 180 / np.pi} degrees')\n",
    "\n",
    "    def forward(self, x, dirs):\n",
    "        x = self.enc_x_func(x)\n",
    "        dirs = self.enc_dir_func(dirs)\n",
    "        curr = self.d1(x)\n",
    "        curr = torch.cat((curr, x), dim=1)\n",
    "        curr = self.d2(curr)\n",
    "        density = torch.nn.functional.relu(curr[:, 1].unsqueeze(1))\n",
    "        # density = curr[:, 1].unsqueeze(1)\n",
    "        colour = torch.sigmoid(curr[:, 1:])\n",
    "        # colour = curr[:, 1:]\n",
    "        return density, colour\n",
    "\n",
    "    def render(self, angle):\n",
    "        angle = torch.tensor(angle)\n",
    "        h = self.max_dist / self.samples_per_ray\n",
    "        camera_pos = torch.tensor([torch.sin(angle), torch.cos(angle)])\n",
    "        camera_dir = -camera_pos\n",
    "        camera_tangent = torch.tensor([-camera_dir[1], camera_dir[0]])\n",
    "        # print(f'camera_pos: {camera_pos}\\n'\n",
    "              # f'camera_dir: {camera_dir}\\n'\n",
    "              # f'camera_tangent: {camera_tangent}')\n",
    "        offsets = torch.linspace(-1, 1, self.res) * self.camera_size / 2\n",
    "        origins = torch.zeros((self.res, 2))\n",
    "        dirs = torch.zeros((self.res, 2))\n",
    "        for i in range(self.res):\n",
    "            origins[i, :] = camera_pos + camera_dir * self.focal_length + offsets[i] * camera_tangent\n",
    "            dirs[i, :] = camera_dir * self.focal_length + offsets[i] * camera_tangent\n",
    "            dirs[i, :] /= dirs[i, :].norm();\n",
    "        \n",
    "        density_so_far = torch.zeros((self.res, 1), device=device, requires_grad=True)\n",
    "        pixels = torch.zeros((self.res, 3), device=device, requires_grad=True)\n",
    "\n",
    "        prev_t = 0\n",
    "        for s in torch.arange(0, self.max_dist, h):\n",
    "            t = s + torch.rand((1,)) * h\n",
    "            # t = s\n",
    "            x = origins + t * dirs\n",
    "\n",
    "            # HERE -------------------------------\n",
    "            density, colour = self(x, dirs)\n",
    "            # HERE -------------------------------\n",
    "\n",
    "            delta = (t - prev_t)\n",
    "\n",
    "            # print(colour)\n",
    "\n",
    "            density_so_far = density_so_far + delta * density\n",
    "            T = torch.exp(-density_so_far)\n",
    "            alpha = 1 - torch.exp(-delta * density)\n",
    "\n",
    "            pixels = pixels + T * alpha * colour\n",
    "            \n",
    "            prev_t = t\n",
    "\n",
    "        return pixels\n",
    "\n",
    "\n",
    "    def train(self, training_angles, training_imgs, num_epochs=25, lr=0.001, block_size=None, print_n=10):\n",
    "        N = len(training_angles)\n",
    "        if block_size == None:\n",
    "            block_size = N\n",
    "        for k in range(num_epochs):\n",
    "            # print(f'\\nepoch {k+1:>3}/{num_epochs} ----------------')\n",
    "            order = torch.randperm(N)\n",
    "            i = 0\n",
    "            for j in range(N // block_size):\n",
    "                s = 0\n",
    "                self.zero_grad()\n",
    "                for p in range(j * block_size, min((j + 1) * block_size, N)):\n",
    "                    sample = order[i]\n",
    "                    theta = training_angles[sample]\n",
    "                    gt_img = training_imgs[sample]\n",
    "                    gen_img = self.render(theta)\n",
    "                    loss = (gt_img - gen_img).norm() ** 2 / block_size\n",
    "                    loss.backward()\n",
    "                    s += loss.item()\n",
    "                    i += 1\n",
    "                n = 0\n",
    "                for param in self.parameters():\n",
    "                    param.data -= param.grad * lr\n",
    "                    n += param.grad.norm().item()\n",
    "            if (k+1) % print_n == 0:\n",
    "                print(f'epoch {k+1}/{num_epochs} loss: {s:>.5}')\n",
    "            # self.plot_example(torch.randint(low=0, high=N, size=(1,)).item())\n",
    "            # plt.figure(figsize=(4,2))\n",
    "            # plt.plot(self.render(0).detach().numpy())\n",
    "\n",
    "res = 100\n",
    "size = 10\n",
    "n = NeRF2d(res=res, enc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afad3ab-800b-48f0-8387-8f906d818aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow_n(theta, ax):\n",
    "    theta = torch.tensor(theta)\n",
    "    field_size = 100\n",
    "    scene = torch.zeros(field_size, field_size, 3)\n",
    "    pts_one_axis = torch.linspace(-1, 1, field_size)\n",
    "    pts = torch.cartesian_prod(pts_one_axis, pts_one_axis)\n",
    "    dirs = torch.tensor([[torch.cos(theta), torch.sin(theta)]]).tile((pts.shape[0], 1))\n",
    "    densities, cols = n(pts, dirs)\n",
    "    scene = (torch.sigmoid(densities - 1).tile((1, 1, 3)) * cols).reshape((field_size, field_size, 3))\n",
    "    print(f'min: {scene.min()} max: {scene.max()}')\n",
    "    # scene = (scene - scene.min()) / (scene.max() - scene.min())\n",
    "    # scene[scene==torch.nan] = scene.mean()\n",
    "    ax.imshow(scene.cpu().detach().numpy())\n",
    "imshow_n(0, plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f817c407-3ad5-4d92-bc5b-00c48f92600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SceneObject:\n",
    "    def __init__(self, centre, size, colour):\n",
    "        self.centre = centre\n",
    "        self.size = size\n",
    "        self.colour = colour\n",
    "\n",
    "class Square(SceneObject):\n",
    "    def sdf(self, p):\n",
    "        return torch.abs(p - self.centre).max() - self.size\n",
    "\n",
    "class Circle(SceneObject):\n",
    "    def sdf(self, p):\n",
    "        return (p - self.centre).norm() - self.size\n",
    "\n",
    "class Scene:\n",
    "    def __init__(self):\n",
    "        self.objects = []\n",
    "    def min_sdf(self, p):\n",
    "        return min([obj.sdf(p) for obj in self.objects])\n",
    "\n",
    "    def closest_object(self, p):\n",
    "        if len(self.objects) == 0:\n",
    "            return None\n",
    "        closest = None\n",
    "        min_sdf = np.inf\n",
    "        for obj in self.objects:\n",
    "            if obj.sdf(p) < min_sdf:\n",
    "                closest = obj\n",
    "                min_sdf = obj.sdf(p)\n",
    "        return closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f948c9c-42c7-4c97-935a-982c6ab882a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def march_ray(scene: Scene, origin, direction, max_dist):\n",
    "    t = 0\n",
    "    dir = direction / direction.norm()\n",
    "    while t < max_dist:\n",
    "        p = origin + t * dir\n",
    "        dist = scene.min_sdf(p)\n",
    "        if dist <= 0.00001:\n",
    "            return scene.closest_object(p).colour\n",
    "        t += dist\n",
    "    return torch.zeros(3)\n",
    "\n",
    "def raymarch_image(scene: Scene, res, focal_length, camera_size, max_dist, theta):\n",
    "    camera_pos = torch.tensor([torch.sin(angle), torch.cos(angle)])\n",
    "    camera_dir = -camera_pos\n",
    "    camera_tangent = torch.tensor([-camera_dir[1], camera_dir[0]])\n",
    "    offsets = torch.linspace(-1, 1, res) * camera_size / 2\n",
    "    pixels = torch.zeros((res, 3))\n",
    "    for i in range(res):\n",
    "        origin = camera_pos + camera_dir * focal_length + offsets[i] * camera_tangent\n",
    "        dir = camera_dir * focal_length + offsets[i] * camera_tangent\n",
    "        dir /= dir.norm();\n",
    "        pixels[i, :] = march_ray(scene, origin, dir, max_dist)\n",
    "    return pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f5a3f3-3411-486f-bc1d-44907519b36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "red = torch.tensor([1, 0, 0])\n",
    "blue = torch.tensor([0, 0, 1])\n",
    "scene = Scene()\n",
    "scene.objects.append(Square(torch.tensor([0.2, 0.1]), 0.1, red))\n",
    "scene.objects.append(Circle(torch.tensor([-0.3, -0.2]), 0.25, blue))\n",
    "print(scene.objects)\n",
    "\n",
    "N = 25\n",
    "angles = torch.rand(N)\n",
    "imgs = []\n",
    "for angle in angles:\n",
    "    print(len(imgs))\n",
    "    imgs.append(raymarch_image(scene, n.res, n.focal_length, n.camera_size, n.max_dist, angle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaa4c66-b145-4526-9b5a-ae5ac84c3ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow_scene(ax):\n",
    "    field_size = 100\n",
    "    pts_one_axis = torch.linspace(-1, 1, field_size)\n",
    "    sdf_field = torch.zeros((field_size, field_size, 3))\n",
    "    for i in range(len(pts_one_axis)):\n",
    "        for j in range(len(pts_one_axis)):\n",
    "            p = torch.tensor([pts_one_axis[i], pts_one_axis[j]])\n",
    "            # print(p, scene.closest_object(p), scene.min_sdf(p))\n",
    "            if scene.min_sdf(p) < 0:\n",
    "                sdf_field[i, j, :] = scene.closest_object(p).colour\n",
    "    ax.imshow(sdf_field.cpu().detach().numpy())\n",
    "imshow_scene(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f73862-de19-478e-871d-4cdb42764cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(i):\n",
    "    cols = ['r', 'g', 'b']\n",
    "    gt_i = imgs[i].cpu().detach().numpy()\n",
    "    render_i = n.render(i).cpu().detach().numpy()\n",
    "    \n",
    "    for j in range(3):\n",
    "        plt.plot(gt_i[:, j], color=cols[j], linestyle=':', label=f'gt  {cols[j]}')\n",
    "        plt.plot(render_i[:, j], color=cols[j], linestyle='--', label=f'gen {cols[j]}')\n",
    "        plt.legend()\n",
    "    \n",
    "    fig, [ax1, ax2] = plt.subplots(1, 2)\n",
    "    imshow_n(angles[i], ax1)\n",
    "    imshow_scene(ax2)\n",
    "compare(torch.randint(N, (1,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c7a8bd-6c56-4064-a039-d35b7664e6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "n.train(angles, imgs, lr=0.02, num_epochs=5, print_n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae290053-17ec-4dd6-a911-373560013420",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(torch.randint(N, (1,)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
